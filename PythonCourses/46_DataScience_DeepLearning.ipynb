{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du Machine Learning au Deep Learning<a id=\"topDeepL\"></a>\n",
    "===\n",
    "\n",
    "**Sommaire**\n",
    "- [1. Introduction](#chap1DeepL)\n",
    "- [2. History](#chap2DeepL)\n",
    "    - [2.1. Réseaux neuronaux (1943)](#chap2-1DeepL)\n",
    "    - [2.2. Perceptron (1957)](#chap2-2DeepL)\n",
    "    - [2.3. Perceptron Multicouche (1986)](#chap2-3DeepL)\n",
    "    - [2.4. ImageNet et l'envol du Deep Learning (2012)](#chap2-4DeepL)\n",
    "- [3. Logique mathématique des perceptron](#chap3DeepL)\n",
    "    - [3.1. La fonction Sigmoïde](#chap3-1DeepL)\n",
    "    - [3.2. La fonction cout](#chap3-2DeepL)\n",
    "    - [3.3. L'algorithme de la descente de gradient](#chap3-3DeepL)\n",
    "    - [3.4. Calcul des gradients](#chap3-4DeepL)\n",
    "    - [3.5. Résumé des calculs](#chap3-5DeepL)\n",
    "- [4. Programmation d'un perceptron](#chap3DeepL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#topDeepL)\n",
    "\n",
    "---\n",
    "\n",
    "# 1. Introduction<a id=\"chap1DeepL\"></a>\n",
    "**Le machine Learning**\n",
    "Machine Learning = domaine d'IA où on va programmer une *machine* capable de trouver les meilleures paramètres pour décrire une courbe afin d'analyser des données.  \n",
    "On va donc créer un algo d'**optimisation** capable de trouver les meilleurs paramètre pour avoir le modèle le plus juste. Il va chercher à **minimiser la distance** entre le **modèle** et les **points** :\n",
    "![](https://puu.sh/HNtSQ/c583f6871d.png)\n",
    "> Donc en gros, on va développer un modèle utilisant des algos d'optimisation pour minimiser les erreurs entre ce dernier et les données.\n",
    "\n",
    "\n",
    "Pleins de modèles existent comme notamment:\n",
    "- Les modèles linéaires (utilisant par exemple la *Descente de Gradients*)\n",
    "- Les arbres de décision (utilisant par exemple l'*Algorithme CART*)\n",
    "- Les Support Vector Machines (utilisant par exemple la *Marge Maximum*)\n",
    "\n",
    "**Et le Deep learning dans tout ça ?**  \n",
    "Le deep learning consiste simplement à utiliser un type de modèle : **Les réseaux de Neurones Artificiels**  \n",
    "Ici, plutôt que d'avoir une fonction à optimiser, nous aurons une série de fonctions (les *neurones*) reliées en *réseau*. Plus il y a de fonctions, plus on dit que le réseau est profond et plus il sera capable de résoudre des problèmes complexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#topDeepL)\n",
    "\n",
    "---\n",
    "\n",
    "# 2. History<a id=\"chap2DeepL\"></a>\n",
    "## 2.1. Réseaux neuronaux (1943)<a id=\"chap2-1DeepL\"></a>\n",
    "Créés en 1943 par Warren McCulloch et Walter Pitts (dans *A logical calculus of the ideas immanent in nervous activity*), ils ont essayé de représenté le fonctionnement des neurones. Un neurone peut recevoir des excitateurs (+1) ou des inibiteurs (-1), si la somme est supérieure à un seuil, ils vont à leur tour emmetre quelque chose.  \n",
    "Nous avons donc une fonction `f` recevant différents signaux `x` (x1, x2, x3, ...) et retournant une valeur `y`. Nous avons deux grande étapes:\n",
    "1. L'**aggrégation**:  \n",
    "```\n",
    "f = w1*x1 + w2*x2 + w3*x3 + ...\n",
    "```\n",
    "Chaque *w* représente un coeficient multiplicateur (dans un neurone nous avons -1 et +1).\n",
    "2. l'**activation**: suivant le résultat précédant, on va décider la valeur à retourner. Par exemple avec 1 ou 0:\n",
    "```\n",
    "y=1  si f>=0\n",
    "y=0  sinon\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chap2-2DeepL\"></a>\n",
    "## 2.2. Perceptron (1957)\n",
    "Le gros problème ici était de trouver les valeurs à adopter. En effet, sans algorithme d'apprentissage, il est nécessaire de saisir ces valeurs à la main.  \n",
    "\n",
    "\n",
    "En 1957, **Frank Rosenblack** invente le **perceptron**, un premier pas vers l'apprentissage, permettant de trouver les valeurs des `w`. Il se repose sur la théorie de **Hebb**: lorsque 2 neurones biologiques s'excitent conjointement, ils renforcent leur lien synaptique: c'est la plasticité synaptique.  \n",
    "La logique du perceptron est d'entrainer le neuronne avec, pour des valeurs de x connus, des valeurs de y connus: à chaque fois qu'une entrée X est activée en même temps qu'une sortie Y, le neurone renforce ses paramètres W; `W = W + a(ytrue - y) * X` où a représente la vitesse d'apprentissage.\n",
    "\n",
    "Par exemple, si y doit etre vrai et que l'on a y faux, alors :\n",
    "```\n",
    "W = W + a(ytrue - y) * X\n",
    "W = W + a(1 - 0) * X\n",
    "W = W + a * X\n",
    "```\n",
    "donc, si on a `f = w1*x1 + w2*x2` avec `x1=1` et `x2=0`, alors :\n",
    "```\n",
    "w1 = w1 + a * 1\n",
    "w1 = w1 + a\n",
    "\n",
    "w2 = w2 + a * 0\n",
    "w2 = w2\n",
    "```\n",
    "\n",
    "A chaque fois que le neurone se trompera, le coeficient *wi* sera augmenté de *a*, jusqu'au moment où l'on dépassera le seuil d'activation et qu'il ne se trompera plus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chap2-3DeepL\"></a>\n",
    "## 2.3. Perceptron Multicouche (1986)\n",
    "Problème : les perceptrons sont linéaires : l'inclinaison dépend de w1 et w2 et la position, de b (le biais) : `f = w1x1 + w2x2 + b`.  \n",
    "Bien que la technique est puissante, on peut séparer deux groupes de points, elle a très vite des problèmes face à la non linéarité des problèmes courant:\n",
    "\n",
    "|Vision linéaire|Monde réel|\n",
    "|:---:|:---:|\n",
    "|![](https://puu.sh/HNumL/3f2d398a29.png)|![](https://puu.sh/HNunw/b5ffa73c9d.png)|\n",
    "|Fonctionnement OK, on sépare correctement les deux groupes|Présence d'erreurs, faux positif / négatifs|\n",
    "\n",
    "En 1986, **Geoffrey Hinton** créat le premier réseau de neuronne artificiel grâce aux **Perceptrons Multicouches**. Le principe est simple, associer plusieurs neurones sur différentes couches afin d'obtenir une fonction non linéaire :\n",
    "![](https://puu.sh/HNupT/488aeaddb7.png)\n",
    "\n",
    "Ici l'entrainement passera par un nouvel algorithme d'apprentissage, le **Back-Propagation**. Le principe est de déterminer comment la **sortie du réseau** varie en fonction des **paramètres (W, b)** de **chaque couche**. On va calculer une **chaîne de Gradients qui indique l'évolution de la sortie suivant la dernière couche, puis comment celle-ci varie en fonction de la couche précédente, et cetera:\n",
    "![](https://puu.sh/HNutG/9af1b872de.png)\n",
    "\n",
    "\n",
    "Pour résumer :\n",
    "1. **Forward propagation** : on fait circuler les données de la première à la dernière couche pour créer une sortie y\n",
    "2. **Cost function** : on va calculer l'erreur entre la sortie y et la sortie y true\n",
    "3. **Back propagation** : on mesure comment la fonction cout varie à chaque couche du modèle en partant de la fin\n",
    "4. **Gradient Descent** : on corrige les gradients avant de reboucler sur la première étape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chap2-4DeepL\"></a>\n",
    "## 2.4. ImageNet et l'envol du Deep Learning (2012)\n",
    "Les réseaux neuronaux ont ensuite grandement évolués aux cours des années 90', mais un grand problème subsistait : l'accès aux données permettant d'entrainer les IA. Il a fallu attendre l'arrivée d'internet et des smartphones pour obtenir cette base de millions de données classée, répertoriée, labelisée et exploitable. Enfin, un second problème était la puissance de calcul encore trop limité durant les années 2000.\n",
    "\n",
    "C'est en 2012, notamment grâce à la compétition *ImageNet* et riche de l'envol d'internet, des smartphones quelques années auparavent, ainsi que de l'augmentation impressionnante de la puissance de GPU que le Deep Learning a pu prendre un nouvel envol avec des résultats intéressants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#topDeepL)\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"chap3DeepL\"></a>\n",
    "# 3. Logique mathématique des perceptron\n",
    "\n",
    "La logique du perceptron est d'entrainer le neurone avec, pour des valeurs de x connus, des valeurs de y connus: à chaque fois qu'une entrée X est activée en même temps qu'une sortie Y, le neurone renforce ses paramètres W; `W = W + a(ytrue - y) * X` où a représente la vitesse d'apprentissage.\n",
    "\n",
    "\n",
    "\n",
    "<a id=\"chap3-1DeepL\"></a>\n",
    "## 3.1. La fonction Sigmoïde\n",
    "On va associer une probabilité à notre décision. Cette dernière nous permettra d'indiquer si notre choix est sûr lorsque l'on est loin de la frontière de décision, ou moins lorsque l'on s'en rapproche. Pour cela on va utiliser une fonction d'activation se rapprochant de 0 ou 1 suivant notre distance à la limite de décision : c'est la fonction **Sigmoïde** ou logistique:\n",
    "```\n",
    "a(z) = 1/(1+e^(-z))\n",
    "```\n",
    "où a(z) représente la probabilité d'appartenir à la classe 1, avec z correspondant à la distance du point au seuil de décision.\n",
    "> Il est important de noter que la probabilité suit ici une loi de **Bernoulli** : `P(Y = g) = a(z)^y * (1 - a(z))^(1-y)`\n",
    "> Donc la probabilité que le point appartienne à la classe 1 est `P(Y = 1) = a(z)` et la probabilité inverse est `P(Y = 0) = 1 - a(z)` :\n",
    "> - `P(Y = 0) = a(z)^0 * (1 - a(z))^(1-0) = 1 * (1 - a(z))`\n",
    "> - `P(Y = 1) = a(z)^1 * (1 - a(z))^(1-1) = a(z) * 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chap3-2DeepL\"></a>\n",
    "## 3.2. La fonction cout\n",
    "Une fonction cout (en machine learning) permet de quantifier les erreurs effectuées par un modèle.\n",
    "\n",
    "On va ici utiliser **Log Loss**.  \n",
    "\n",
    "Pour évaluer la performance du modèle, on va utiliser la **Vraisemblance**. En statistique, cela indique la plausibilité du modèle face à des données vraies. Pour cela on va utiliser ce que l'on a vu au dessus et on va regarder la probabilité que ce que l'on suppose vrai, le soit :\n",
    "![](https://puu.sh/HNwWb/83af7737f0.png)\n",
    "\n",
    "Si la vraisemblance est proche de 100%, alors notre modèle est fortement vraisemblable, et vice versa. Cependant, plus on a de valeurs, plus la multiplication de ces dernières entre elles va conduire la vraisemblance à tendre vers 0. Pour palier à cela, on va utiliser un logarithme sachant que `log(ab) = log(a) + log(b)`, plutot que les multiplier, on va les additionner.  \n",
    "Maintenant, en simplifiant la fonction, on va retrouver (presque) la fonction log loss :\n",
    "![](https://puu.sh/HNx14/55e2ba360a.png)\n",
    "\n",
    "Ce petit facteur que l'on trouve au début est très simple à expliquer:\n",
    "- Là, on cherche à maximiser la vraisemblance. Cependant, une fonction max n'existe pas en mathématiques. On va donc chercher à la minimiser sachant que `max(f(x)) = min(-f(x))`, d'où la présence du `-`.\n",
    "- `1/m` permet simplement de normaliser le résultat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chap3-3DeepL\"></a>\n",
    "## 3.3. L'algorithme de la descente de gradient\n",
    "\n",
    "On cherche à minimiser les erreurs (donc Log Loss) en jouant sur les `W` et `b`.  \n",
    "Pour cela, on va donc regarder comment la fonction varie en fonction des paramètres en calculant la dérivée (donc le gradient) de la fonction coût:\n",
    "```\n",
    "Wt+1 = Wt - a * dL/dWt\n",
    "```\n",
    "\n",
    "Avec \n",
    "- Wt+1, W à l'instant t+1\n",
    "- Wt, W à l'instant t, Wt+1\n",
    "- a le pas d'apprentissage\n",
    "- dL/dWt, la Gradient à l'instant t \n",
    "\n",
    "Ainsi si le gradient baisse, Wt+1 va augmenter et vice versa.\n",
    "\n",
    "> ATTENTION, il faut que la fonction soit convexe sinon on risque de tomber sur un minimum local et non le minimum global !\n",
    "> C'est le cas de Log Loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chap3-4DeepL\"></a>\n",
    "## 3.4. Calcul des gradients\n",
    "\n",
    "Calculons maintenant les gradients:\n",
    "- $\\frac{\\delta L}{\\delta w_1}$\n",
    "- $\\frac{\\delta L}{\\delta w_2}$\n",
    "- $\\frac{\\delta L}{\\delta b}$\n",
    "\n",
    "Il est intéressant de notre que l'on n'a pas $wi$ dans L. Pour ça il faudrait transformer $a$ puis transformer $Z$... C'est long et lourd. Pour simplifier, on va utiliser la *règle des chaines*:\n",
    "$$\\frac{\\delta L}{\\delta w_i} = \\frac{\\delta L}{\\delta a} * \\frac{\\delta a}{\\delta Z} * \\frac{\\delta Z}{\\delta w_i}$$\n",
    "\n",
    "Rappelons $L$, \n",
    "$$L = \\frac{-1}{m} \\sum_{m}^{i=1} y^{(1)}.log(a^{(1)}) + (1 - y^{(1)}).log(1 - a^{(1)})$$\n",
    "\n",
    "---\n",
    "\n",
    "• **Première dérivée**  \n",
    "On va donc commencer par $\\frac{\\delta L}{\\delta a}$ dériver $log(a)$, donc le logarithme naturel de $a$. La dérivée usuelle de log est $\\frac{1}{x}$, donc $\\frac{\\delta L}{\\delta a} = \\frac{-1}{m} \\sum_{m}^{i=1} y.\\frac{1}{a} + (1 - y).\\frac{-1}{1-a}$, donc on a :\n",
    "$$\\frac{\\delta L}{\\delta a} = \\frac{-1}{m} \\sum_{m}^{i=1} \\frac{y}{a} - \\frac{1 - y}{1-a}$$\n",
    "\n",
    "---\n",
    "\n",
    "• **Deuxième dérivée**  \n",
    "Continuons avec $\\frac{\\delta a}{\\delta Z}$. On peut représenter $a$ avec $a=g•f=g(f(z))$ avec :\n",
    "- $g = \\frac{1}{f}$\n",
    "- $f = 1 + e^{-Z}$\n",
    "\n",
    "De plus, $(g•f)' = g'f(Z) * f'(Z)$, donc :\n",
    "- Sachant que $(x^\\alpha)' = \\alpha x^{\\alpha - 1}$ alors on a $g = \\frac{1}{f} = -x^{-2} = -\\frac{1}{x^2}$\n",
    "- Sachant que $(e^{\\alpha x})' = \\alpha e^{\\alpha x}$, on a alors $f = 1 + e^{-Z} = -e^{-Z}$\n",
    "\n",
    "Donc la dérivée partielle de $a$ par rapport à $Z$ est :\n",
    "$$\\frac{\\delta a}{\\delta Z} = \\frac{-1}{(1+e^{-Z})^2} * -e^{-Z} = \\frac{e^{-Z}}{(1+e^{-Z})^2}$$\n",
    "\n",
    "Ce calcul peut être simplifié... Ce calcul ressemble beaucoup au calcul de $a$. En effet,  on peut dire que $\\frac{e^{-Z}}{(1+e^{-Z})^2} = \\frac{1}{1 + e^{-Z}} * \\frac{e^{-Z}}{1 + e^{-Z}} = a(Z) * \\frac{e^{-Z}}{1 + e^{-Z}}$. On peut encore le simplifier avec un petit trick mathématique :\n",
    "\n",
    "$$\\frac{e^{-Z}}{1 + e^{-Z}} = \\frac{e^{-Z} +1-1}{1 + e^{-Z}} = \\frac{e^{-Z} + 1}{1 + e^{-Z}}  -\\frac{1}{1 + e^{-Z}} = 1  - a(Z)$$\n",
    "\n",
    "DONC, finalement on a :\n",
    "$$\\frac{\\delta a}{\\delta Z} = a(Z) * (1 - a(Z))$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "• **Troisième dérivée**  \n",
    "\n",
    "Passons enfin à $\\frac{\\delta Z}{\\delta w_i}$, ça va être très rapide :\n",
    "$$\\frac{\\delta Z}{\\delta w_1} = \\frac{(w_1 x_1 + w_2 x_2 + b)'}{w_1} = x_1$$\n",
    "\n",
    "Car oui, selon $w_1$, le reste n'est que constante donc est égale à 0 quand on dérive.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Dérivée finale**\n",
    "\n",
    "Donc, on a :  \n",
    "$$\n",
    "\\frac{\\delta L}{\\delta w_1} = \\frac{\\delta L}{\\delta a} * \\frac{\\delta a}{\\delta Z} * \\frac{\\delta Z}{\\delta w_1} = (\\frac{-1}{m} \\sum_{m}^{i=1} \\frac{y}{a} - \\frac{1 - y}{1-a}) * (a(Z) * (1 - a(Z))) * (x_1)\\\\\n",
    " = \\frac{-1}{m} \\sum_{m}^{i=1}[ y (1 - a) - a (1 - y) ] * x_1\\\\\n",
    " = \\frac{-1}{m} \\sum_{m}^{i=1}[ y - a*y - a + y*a] * x_1\\\\\n",
    " = \\frac{-1}{m} \\sum_{m}^{i=1}[ y - a] * x_1\\\\\n",
    " = \\frac{-1}{m} \\sum_{m}^{i=1}[y^{(i)} - a^{(i)}] * x_1^{(i)}\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "On peut aussi l'écrire :\n",
    "$$\\frac{1}{m} \\sum_{m}^{i=1}[a^{(i)} - y^{(i)}] * x_1^{(i)}$$\n",
    "\n",
    "\n",
    "---\n",
    "**Gradient**\n",
    "\n",
    "Finalement pour les autres gradients, on a juste à changer la troisième dérivée, nous donnant donc :\n",
    "$$\n",
    "\\frac{\\delta L}{\\delta w_1} = \\frac{1}{m} \\sum_{m}^{i=1}[a^{(i)} - y^{(i)}] * x_1^{(i)}\\\\\n",
    "\\frac{\\delta L}{\\delta w_2} = \\frac{1}{m} \\sum_{m}^{i=1}[a^{(i)} - y^{(i)}] * x_2^{(i)}\\\\\n",
    "\\frac{\\delta L}{\\delta b}   = \\frac{1}{m} \\sum_{m}^{i=1}[a^{(i)} - y^{(i)}]\\\\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chap3-5DeepL\"></a>\n",
    "## 3.5. Résumé des calculs\n",
    "\n",
    "Pour résumer, on a cherché à développer un neuronne qui a 2 entrées *x_i*, auxquelles il va associer des poids *w_i* afin d'obtenir en sortie *y*, une prédiction. Ce neuronne aura pour but de séparer linéairement deux groupes d'éléments. \n",
    "\n",
    "Dans le neuronne on va retrouver deux fonctions :\n",
    "- Une fonction linéaire : $Z = w_1*x_1 + w_2*x_2 + b$ (avec $b$ étant un biais)\n",
    "- Puis une fonction d'activation, la fonction *Sigmoïde* : $a = \\frac{1}{1 + e^{-Z}}$\n",
    "\n",
    "On veux donc que le neuronne respecte le plus fidèlement possible le problème, donc pour cela, on cherche à minimiser une fonction coût, *Log Loss* : $L = \\frac{-1}{m} \\sum_{m}^{i=1} y^{(1)}.log(a^{(1)}) + (1 - y^{(1)}).log(1 - a^{(1)})$\n",
    "\n",
    "Pour minimiser cette fonction, on va utiliser un algorithme d'optimisation, la *Descente de Gradient* : \n",
    "- $w_i = w_i - \\alpha\\frac{\\delta L}{\\delta w_i}$\n",
    "- $b = b - \\alpha\\frac{\\delta L}{\\delta b}$\n",
    "\n",
    "Où $\\frac{\\delta L}{\\delta w}$ est le *Gradient* de la fonction coût (sa dérivée), que l'on mettra à jour petit à petit, selon un pas $\\alpha$. Ces derniers sont représentés par la fonction suivante : \n",
    "- $\\frac{\\delta L}{\\delta w_1} = \\frac{1}{m} \\sum_{m}^{i=1}[a^{(i)} - y^{(i)}] * x_1^{(i)}$\n",
    "- $\\frac{\\delta L}{\\delta w_2} = \\frac{1}{m} \\sum_{m}^{i=1}[a^{(i)} - y^{(i)}] * x_2^{(i)}$\n",
    "- $\\frac{\\delta L}{\\delta b}   = \\frac{1}{m} \\sum_{m}^{i=1}[a^{(i)} - y^{(i)}]$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#topDeepL)\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"chap4DeepL\"></a>\n",
    "# 4. Programmation d'un perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(X):\n",
    "    W = np.random.randn(X.shape[1], 1)\n",
    "    b = np.random.randn(1)\n",
    "    return (W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, W, b):\n",
    "    Z = X.dot(W) + b\n",
    "    A = sigmoid(Z)\n",
    "    return A\n",
    "\n",
    "def log_loss(y, A):\n",
    "    return 1/len(y) * np.sum(-y * np.log(A) - (1 - y) * np.log(1 - A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(X, A, y):\n",
    "    dW = 1/len(y) * np.dot(X.T, A - y)\n",
    "    db = 1/len(y) * np.sum(A - y)\n",
    "    return (dW, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimisation(X, W, b, A, y, learning_rate):\n",
    "    dW, db = gradients(X, A, y)\n",
    "    W = W - learning_rate * dW\n",
    "    b = b - learning_rate * db\n",
    "    return (W, b)\n",
    "\n",
    "def predict(X, W, b):\n",
    "    A = forward_propagation(X, W, b)\n",
    "    return A >= .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PERCEPTRON MULTICOUCHE\n",
    "\n",
    "def forward_propagation(X, params):\n",
    "    W1 = params['W1']\n",
    "    b1 = params['b1']\n",
    "    W2 = params['W2']\n",
    "    b2 = params['b2']\n",
    "    \n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    cache = {\n",
    "        'A1': A1,\n",
    "        'A2': A2\n",
    "    }\n",
    "    \n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(X, y, params, cache):\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "    W2 = params['W2']\n",
    "    \n",
    "    m = y.shape[1]\n",
    "    \n",
    "    dZ2 = A2 - y\n",
    "    dW2 = 1/m * dZ2.dot(A1.T)\n",
    "    db2 = 1/m * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    \n",
    "    dZ1 = np.dot(W2.T, dZ2) * A1 * (1 - A1)\n",
    "    dW1 = 1/m * dZ1.dot(X.T)\n",
    "    db1 = 1/m * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DEEP LEARNING\n",
    "\n",
    "# Pytorch\n",
    "import torch \n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thibault **Santonja**  \n",
    "2021"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
