{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://puu.sh/HLHgF/324c7fedc3.png)\n",
    "\n",
    "\n",
    "Most important basis :\n",
    "- [x] Python\n",
    "\t- [x] Data manipulation using Pandas & Numpy\n",
    "\t- [x] Data visualization using Matplotlib\n",
    "- [x] SQL\n",
    "\t- [x] SQL & Pandas & SQLite (Good course : https://medium.com/analytics-vidhya/programming-with-databases-in-python-using-sqlite-4cecbef51ab9)\n",
    "\t- [x] platforms like Mode Analytics and Databricks to easily work with Python and SQL.\n",
    "- Statistics basis \n",
    "\t- [x] Learn : Sampling, frequency distributions, Mean, Median, Mode, Measure of variability, Probability basics, significant testing, standard deviation, z-scores, confidence intervals, and hypothesis testing (including A/B testing)\n",
    "\t- Good Handbook (especially first four chapters) : https://www.amazon.com/Practical-Statistics-Data-Scientists-Essential/dp/9352135652\n",
    "\t- Learn *StatsModels* Python Library + good video course : https://www.youtube.com/watch?v=yaSgoGLXKOg\n",
    "- Machine Learning using Scikit-Learn (Good video course by Andrew Ng : https://www.coursera.org/learn/machine-learning + Good Handbook and exercise : https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291 )\n",
    "\n",
    "Next :\n",
    "- big data technologies like Spark and Hadoop\n",
    "- Google Analytics \n",
    "- Python data viz using **Seaborn**, Bokeh, Pygal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([55.75608173, 52.81238965, 55.62111732, 49.89528542, 56.05333946,\n",
       "        41.22825435, 55.48902971, 48.39043528, 51.42119142, 49.98761722,\n",
       "        50.37643254, 59.28903873, 48.06409926, 51.71440901, 47.47399008,\n",
       "        44.98892566, 50.89196949, 54.29815175, 52.66891552, 48.14687677,\n",
       "        48.85774544, 44.7906864 , 57.52047777, 48.30737622, 49.52319116,\n",
       "        45.86263123, 46.38149512, 38.33135014, 48.22734687, 53.02997041,\n",
       "        46.82664881, 56.74863347, 36.50340832, 57.77302102, 59.83695815,\n",
       "        58.66702393, 40.17525716, 46.75294991, 45.40265986, 60.06444145,\n",
       "        44.76302813, 52.85506209, 58.24064082, 54.23672568, 48.372648  ,\n",
       "        50.39410706, 55.4292295 , 49.05461773, 55.17942781, 53.98496247,\n",
       "        45.27885551, 55.84814236, 56.49557576, 52.77333886, 48.73193272,\n",
       "        48.8257024 , 49.0600586 , 39.64540498, 58.37394186, 53.60776   ,\n",
       "        44.99844929, 51.42698252, 49.73851062, 41.21045468, 43.46278467,\n",
       "        47.10338127, 46.59610411, 51.55468165, 49.79632054, 48.63102467,\n",
       "        40.72154258, 44.63665191, 51.46848094, 50.52421782, 48.97616849,\n",
       "        50.75697162, 50.2559305 , 45.91111679, 52.61437799, 54.00169745,\n",
       "        45.47815227, 41.502261  , 44.25342906, 41.69792207, 45.89050187,\n",
       "        51.45690452, 49.06184611, 54.57222172, 46.81239719, 51.77984437,\n",
       "        47.09997212, 53.04287524, 54.46955623, 45.30606873, 53.29892428,\n",
       "        56.40239392, 47.01915711, 44.6138216 , 48.51625342, 44.39357566]),\n",
       " array([45, 45, 55, 47, 43, 46, 56, 52, 49, 44, 51, 45, 54, 49, 49, 45, 54,\n",
       "        47, 47, 48, 56, 55, 50, 50, 53, 51, 46, 53, 46, 51, 55, 54, 52, 47,\n",
       "        57, 41, 49, 58, 54, 46, 44, 56, 52, 54, 52, 47, 55, 44, 53, 47, 58,\n",
       "        43, 41, 47, 53, 46, 55, 42, 46, 47, 46, 49, 40, 41, 58, 52, 49, 52,\n",
       "        50, 53, 45, 46, 47, 47, 53, 51, 47, 52, 57, 52, 43, 48, 56, 50, 45,\n",
       "        55, 54, 52, 48, 49, 56, 45, 50, 51, 38, 48, 46, 52, 53, 49]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate artificial data\n",
    "size = 100  # Output shape\n",
    "loc = 50    # Mean (“centre”) of the distribution\n",
    "scale = 5   # Standard deviation (spread or “width”) of the distribution. Must be non-negative.\n",
    "\n",
    "\n",
    "X = np.random.normal(loc, scale, size)\n",
    "\n",
    "# Y = np.random.randint(10, size=100)\n",
    "# Y = np.random.binomial(n=100, p=.5, size=100)\n",
    "Y = stats.norm.ppf(np.random.random(size), loc=loc, scale=scale).astype(int)\n",
    "\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X mean : 0.975\n",
      "Y mean : 50.000\n"
     ]
    }
   ],
   "source": [
    "# Mean\n",
    "print('X mean : %.3f' % X.mean())\n",
    "print('Y mean : %.3f' % Y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X median : 0.984901\n",
      "Y median : 49\n"
     ]
    }
   ],
   "source": [
    "# Median\n",
    "print('X median : %f' % np.median(X))\n",
    "print('Y median : %d' % np.median(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.04442572, 1.06060007, 0.81992574, 1.25394092, 0.91576459,\n",
       "        0.8708394 , 0.68022311, 0.51832   , 0.9841502 , 0.65597501]),\n",
       " array([64, 44, 55, 55, 37, 45, 45, 44, 40, 43]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling\n",
    "# We can use numpy random.choice() or take a value from the array each n values\n",
    "np.random.choice(X, 10), np.random.choice(Y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    counts\n",
       "22       1\n",
       "30       2\n",
       "31       1\n",
       "32       1\n",
       "33       4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequency distributions\n",
    "unique, counts = np.unique(Y, return_counts=True)\n",
    "pd.DataFrame({'counts': counts}, index=unique).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.518 to 0.609</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.609 to 0.699</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.699 to 0.790</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.790 to 0.880</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.880 to 0.970</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.970 to 1.061</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.061 to 1.151</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.151 to 1.241</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.241 to 1.332</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.332 and more</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                counts\n",
       "0.518 to 0.609       2\n",
       "0.609 to 0.699       8\n",
       "0.699 to 0.790       7\n",
       "0.790 to 0.880      16\n",
       "0.880 to 0.970      13\n",
       "0.970 to 1.061      20\n",
       "1.061 to 1.151      15\n",
       "1.151 to 1.241      12\n",
       "1.241 to 1.332       3\n",
       "1.332 and more       4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequency distributions on continous\n",
    "def continous_frequency_distributions(array, parts):\n",
    "    min_val = array.min()\n",
    "    max_val = array.max()\n",
    "    steps = np.arange(start=min_val, stop=max_val, step=(max_val-min_val)/parts)\n",
    "    ranges = []\n",
    "    counts = []\n",
    "    \n",
    "    for i in range(parts-1):\n",
    "        ranges.append(str('%.3f' % steps[i]) + ' to ' + str('%.3f' % steps[i+1]))\n",
    "        counts.append(((steps[i] <= array) & (steps[i+1] > array)).sum())\n",
    "        \n",
    "    ranges.append(str('%.3f' % steps[i+1]) + ' and more')\n",
    "    counts.append(((steps[i+1] <= array) & (max_val >= array)).sum())\n",
    "    \n",
    "    return pd.DataFrame({'counts': counts}, index=ranges)\n",
    "\n",
    "\n",
    "continous_frequency_distributions(X, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For discrete :\n",
      "ModeResult(mode=array([47]), count=array([7]))\n",
      "\n",
      "For continous :\n",
      "counts    20\n",
      "Name: 0.970 to 1.061, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mode\n",
    "print('For discrete :')\n",
    "print(stats.mode(Y))\n",
    "\n",
    "print('\\nFor continous :')\n",
    "distrib = continous_frequency_distributions(X, 10)\n",
    "print(distrib.loc[distrib.counts.idxmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X variance : 0.037\n",
      "Y variance : 109.340\n"
     ]
    }
   ],
   "source": [
    "# Measure of variability\n",
    "print('X variance : %.3f' % np.var(X))\n",
    "print('Y variance : %.3f' % np.var(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X deviation : 0.191\n",
      "Y deviation : 10.457\n"
     ]
    }
   ],
   "source": [
    "# standard deviation\n",
    "print('X deviation : %.3f' % np.std(X))  # or print('X deviation : %.3f' % np.var(X)**.5)\n",
    "print('Y deviation : %.3f' % np.std(Y))  # or print('Y deviation : %.3f' % np.var(Y)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.23280414,  1.33243607,  0.49577916, -0.92418258, -1.17824276,\n",
       "         1.10513   , -1.69266842, -0.30751556,  0.0461295 , -0.94610462,\n",
       "        -0.99115016, -1.77078796,  1.57808688, -0.66137017,  0.63121064,\n",
       "         0.9188453 , -1.83580299, -0.74877729, -0.45030274, -1.35585434,\n",
       "        -0.09005113, -1.53596331,  0.95344844,  0.62995115,  0.84093276,\n",
       "         0.87426684,  0.69098409, -1.50902886, -2.38856301, -0.55683417,\n",
       "        -0.39340673,  1.11984537,  0.91250666,  0.82242233,  0.09994879,\n",
       "         1.05416861, -0.542974  ,  0.31988675,  0.74630856,  0.37828739,\n",
       "        -0.09417247,  0.3923616 , -0.31129244,  0.30131909,  2.33593489,\n",
       "         1.8784122 , -1.66909992,  0.0081877 , -0.49785344,  0.4303887 ,\n",
       "         0.65002867,  1.17968167, -0.0197411 , -0.05186291, -0.81220052,\n",
       "        -1.12518691,  1.67598644, -0.98618553,  0.81623257, -0.54609691,\n",
       "         0.37065767, -0.49465347, -1.2761802 , -0.96392332, -1.54236561,\n",
       "         1.94918211,  1.95749146,  1.45620866,  1.18931551, -0.65827009,\n",
       "         0.43133644,  0.13730306,  0.16126291,  0.95689987,  1.00773505,\n",
       "        -0.13160067,  0.13018733, -0.68409475,  0.84564412, -1.93788481,\n",
       "         0.05398133,  0.07393025,  0.01022361,  0.86239296, -0.68561192,\n",
       "        -0.88482714, -0.22483262, -0.94764871,  0.93515259, -0.35630488,\n",
       "        -1.04949199,  0.8242705 , -1.63801371, -0.75766183,  0.36116352,\n",
       "        -0.27920842,  0.44569984,  0.60461906,  1.23740803, -0.94813176]),\n",
       " array([ 1.24323669,  1.24323669,  0.        ,  0.95633591, -0.47816796,\n",
       "         0.66943514,  0.95633591,  0.        , -0.47816796, -1.91267183,\n",
       "        -0.66943514,  0.76506873, -0.66943514,  1.24323669, -0.57380155,\n",
       "        -1.62577105, -0.28690077,  0.38253437, -0.28690077, -0.57380155,\n",
       "        -0.86070232, -1.72140464, -0.86070232, -1.62577105,  0.28690077,\n",
       "         0.        , -1.91267183, -0.66943514, -0.28690077,  0.        ,\n",
       "         0.09563359,  2.00830542,  0.28690077,  2.10393901, -1.1476031 ,\n",
       "         1.0519695 ,  0.47816796, -0.86070232,  0.47816796,  0.57380155,\n",
       "         0.66943514,  1.1476031 , -0.47816796,  0.        , -0.19126718,\n",
       "         0.57380155, -2.67774056,  0.28690077,  0.47816796, -1.24323669,\n",
       "         2.48647337,  1.72140464, -1.0519695 ,  0.19126718,  0.76506873,\n",
       "        -0.76506873,  0.57380155, -1.0519695 ,  1.24323669,  0.38253437,\n",
       "        -0.28690077,  0.47816796, -0.66943514,  0.95633591,  1.62577105,\n",
       "        -0.95633591, -0.95633591,  0.28690077, -0.09563359, -0.28690077,\n",
       "        -0.09563359, -0.76506873, -1.0519695 , -0.38253437, -0.28690077,\n",
       "        -0.19126718,  2.29520619,  1.33887028, -0.57380155, -0.57380155,\n",
       "        -0.28690077,  0.09563359,  1.0519695 ,  1.43450387, -0.38253437,\n",
       "        -1.62577105,  0.66943514,  1.0519695 ,  0.86070232, -1.81703824,\n",
       "         0.57380155, -1.62577105, -0.66943514, -0.09563359, -0.47816796,\n",
       "         0.28690077,  0.66943514, -0.57380155,  1.24323669, -0.57380155]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z-scores\n",
    "stats.zscore(X), stats.zscore(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40.080142407751836, 59.919857592248164)\n",
      "(36.870547397068336, 63.129452602931664)\n"
     ]
    }
   ],
   "source": [
    "# confidence intervals\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "print(stats.t.interval(alpha=0.95, df=size, loc=loc, scale=scale))\n",
    "\n",
    "#create 99% confidence interval for same sample\n",
    "print(stats.t.interval(alpha=0.99, df=size, loc=loc, scale=scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m-h, m+h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability basics\n",
    "\n",
    "# significant testing\n",
    "\n",
    "# hypothesis testing (including A/B testing)\n",
    "# https://towardsdatascience.com/the-math-behind-a-b-testing-with-example-code-part-1-of-2-7be752e1d06f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "à voir :\n",
    "- base formation deep learning https://youtu.be/XUFLq6dKQok\n",
    "- https://databricks.com/blog/2021/05/27/introducing-databricks-machine-learning-a-data-native-collaborative-full-ml-lifecycle-solution.html\n",
    "- https://data-flair.training/blogs/python-descriptive-statistics/\n",
    "- 12 data science apps https://www.youtube.com/watch?v=JwSS70SZdyM\n",
    "- question data science interview : https://www.youtube.com/watch?v=4Z6lxfglvUU\n",
    "\n",
    "Google Earth Engine :\n",
    "- https://earthengine.google.com/\n",
    "- https://towardsdatascience.com/tagged/google-earth-engine\n",
    "- https://www.youtube.com/watch?v=I-wFYm4Hnhg\n",
    "\n",
    "ESA :\n",
    "- [Φ-Lab](https://en.wikipedia.org/wiki/Phi_Lab)\n",
    "- Patrick Griffiths 3rd degree connection 3rd --- EO Data Engineer at European Space Agency - ESA \n",
    "- Sara Aparício 2nd degree connection 2nd --- Earth Observation Data Scientist @ European Space Agency \n",
    "- HIRING Giuseppe Borghi 2nd degree connection 2nd --- Head of the Φ-lab Division at European Space Agency - ESA Earth Observation Programmes Directorate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning & Machine Learning\n",
    "**The easiest takeaway for understanding the difference between machine learning and deep learning is to know that deep learning is machine learning.**\n",
    "- **Machine learning** is an application of AI that includes algorithms that parse data, learn from that data, and then apply what they’ve learned to make informed decisions. \n",
    "- **Deep learning** is a subfield of machine learning that structures algorithms in layers to create an \"artificial neural network” that can learn and make intelligent decisions on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./Ressources/Practical Statistics for Data Scientists.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1c37fa245b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"./Ressources/Practical Statistics for Data Scientists.pdf\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 1. Intro Deep Learning\n",
    "**Le machine Learning**\n",
    "Machine Learning = domaine d'IA où on va programmer une *machine* capable de trouver les meilleures paramètres pour décrire une courbe afin d'analyser des données.  \n",
    "On va donc créer un algo d'**optimisation** capable de trouver les meilleurs paramètre pour avoir le modèle le plus juste. Il va chercher à **minimiser la distance** entre le **modèle** et les **points** :\n",
    "![](https://puu.sh/HNtSQ/c583f6871d.png)\n",
    "> Donc en gros, on va développer un modèle utilisant des algos d'optimisation pour minimiser les erreurs entre ce dernier et les données.\n",
    "\n",
    "\n",
    "Pleins de modèles existent comme notamment:\n",
    "- Les modèles linéaires (utilisant par exemple la *Descente de Gradients*)\n",
    "- Les arbres de décision (utilisant par exemple l'*Algorithme CART*)\n",
    "- Les Support Vector Machines (utilisant par exemple la *Marge Maximum*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Et le Deep learning dans tout ça ?**  \n",
    "Le deep learning consiste simplement à utiliser un type de modèle : **Les réseaux de Neurones Artificiels**  \n",
    "Ici, plutôt que d'avoir une fonction à optimiser, nous aurons une série de fonctions (les *neurones*) reliées en *réseau*. Plus il y a de fonctions, plus on dit que le réseau est profond et plus il sera capable de résoudre des problèmes complexes.\n",
    "\n",
    "\n",
    "## 2. History\n",
    "### 2.1. Réseaux neuronaux (1943)\n",
    "Créés en 1943 par Warren McCulloch et Walter Pitts (dans *A logical calculus of the ideas immanent in nervous activity*), ils ont essayé de représenté le fonctionnement des neurones. Un neurone peut recevoir des excitateurs (+1) ou des inibiteurs (-1), si la somme est supérieure à un seuil, ils vont à leur tour emmetre quelque chose.  \n",
    "Nous avons donc une fonction `f` recevant différents signaux `x` (x1, x2, x3, ...) et retournant une valeur `y`. Nous avons deux grande étapes:\n",
    "1. L'**aggrégation**:  \n",
    "```\n",
    "f = w1*x1 + w2*x2 + w3*x3 + ...\n",
    "```\n",
    "Chaque *w* représente un coeficient multiplicateur (dans un neurone nous avons -1 et +1).\n",
    "2. l'**activation**: suivant le résultat précédant, on va décider la valeur à retourner. Par exemple avec 1 ou 0:\n",
    "```\n",
    "y=1  si f>=0\n",
    "y=0  sinon\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous allons utiliser Python et surtout la librairie Numpy.\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Perceptron (1957)\n",
    "Le gros problème ici était de trouver les valeurs à adopter. En effet, sans algorithme d'apprentissage, il est nécessaire de saisir ces valeurs à la main.  \n",
    "\n",
    "\n",
    "En 1957, **Frank Rosenblack** invente le **perceptron**, un premier pas vers l'apprentissage, permettant de trouver les valeurs des `w`. Il se repose sur la théorie de **Hebb**: lorsque 2 neurones biologiques s'excitent conjointement, ils renforcent leur lien synaptique: c'est la plasticité synaptique.  \n",
    "La logique du perceptron est d'entrainer le neuronne avec, pour des valeurs de x connus, des valeurs de y connus: à chaque fois qu'une entrée X est activée en même temps qu'une sortie Y, le neurone renforce ses paramètres W; `W = W + a(ytrue - y) * X` où a représente la vitesse d'apprentissage.\n",
    "\n",
    "Par exemple, si y doit etre vrai et que l'on a y faux, alors :\n",
    "```\n",
    "W = W + a(ytrue - y) * X\n",
    "W = W + a(1 - 0) * X\n",
    "W = W + a * X\n",
    "```\n",
    "donc, si on a `f = w1*x1 + w2*x2` avec `x1=1` et `x2=0`, alors :\n",
    "```\n",
    "w1 = w1 + a * 1\n",
    "w1 = w1 + a\n",
    "\n",
    "w2 = w2 + a * 0\n",
    "w2 = w2\n",
    "```\n",
    "\n",
    "A chaque fois que le neurone se trompera, le coeficien *wi* sera augmenté de *a*, jusqu'au moment où l'on dépassera le seuil d'activation et qu'il ne se trompera plus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Perceptron Multicouche (1986)\n",
    "Problème : les perceptrons sont linéaires : l'inclinaison dépend de w1 et w2 et la position, de b (le biais) : `f = w1x1 + w2x2 + b`.  \n",
    "Bien que la technique est puissante, on peut séparer deux groupes de points, elle a très vite des problèmes face à la non linéarité des problèmes courant:\n",
    "\n",
    "|Vision linéaire|Monde réel|\n",
    "|:---:|:---:|\n",
    "|![](https://puu.sh/HNumL/3f2d398a29.png)|![](https://puu.sh/HNunw/b5ffa73c9d.png)|\n",
    "|Fonctionnement OK, on sépare correctement les deux groupes|Présence d'erreurs, faux positif / négatifs|\n",
    "\n",
    "En 1986, **Geoffrey Hinton** créat le premier réseau de neuronne artificiel grâce aux **Perceptrons Multicouches**. Le principe est simple, associer plusieurs neurones sur différentes couches afin d'obtenir une fonction non linéaire :\n",
    "![](https://puu.sh/HNupT/488aeaddb7.png)\n",
    "\n",
    "Ici l'entrainement passera par un nouvel algorithme d'apprentissage, le **Back-Propagation**. Le principe est de déterminer comment la **sortie du réseau** varie en fonction des **paramètres (W, b)** de **chaque couche**. On va calculer une **chaîne de Gradients qui indique l'évolution de la sortie suivant la dernière couche, puis comment celle-ci varie en fonction de la couche précédente, et cetera:\n",
    "![](https://puu.sh/HNutG/9af1b872de.png)\n",
    "\n",
    "\n",
    "Pour résumer :\n",
    "1. **Forward propagation** : on fait circuler les données de la première à la dernière couche pour créer une sortie y\n",
    "2. **Cost function** : on va calculer l'erreur entre la sortie y et la sortie y true\n",
    "3. **Back propagation** : on mesure comment la fonction cout varie à chaque couche du modèle en partant de la fin\n",
    "4. **Gradient Descent** : on corrige les gradients avant de reboucler sur la première étape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. ImageNet et l'envol du Deep Learning (2012)\n",
    "Les réseaux neuronaux ont ensuite grandement évolués aux cours des années 90', mais un grand problème subsistait : l'accès aux données permettant d'entrainer les IA. Il a fallu attendre l'arrivée d'internet et des smartphones pour obtenir cette base de millions de données classée, répertoriée, labelisée et exploitable. Enfin, un second problème était la puissance de calcul encore trop limité durant les années 2000.\n",
    "\n",
    "C'est en 2012, notamment grâce à la compétition *ImageNet* et riche de l'envol d'internet, des smartphones quelques années auparavent, ainsi que de l'augmentation impressionnante de la puissance de GPU que le Deep Learning a pu prendre un nouvel envol avec des résultats intéressants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1. PyTorch\n",
    "[Cheatsheet](https://pytorch.org/tutorials/beginner/ptcheat.html)\n",
    "```python\n",
    "import torch \n",
    "```\n",
    "\n",
    "### 2.4.2. TensorFlow\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "import torch \n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
